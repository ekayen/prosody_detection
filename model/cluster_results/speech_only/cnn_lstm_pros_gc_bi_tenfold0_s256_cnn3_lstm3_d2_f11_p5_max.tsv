	epochs	train_losses	train_accs	dev_accs
0	0	0.9965652227401733	0.45384916663040165	0.4554603056280283
1	1	0.8463759422302246	0.5515035467165673	0.5501304509877003
2	2	0.6939166784286499	0.5461508333695984	0.5441669772642564
3	3	0.6920281052589417	0.5515035467165673	0.5501304509877003
4	4	0.693414032459259	0.5515035467165673	0.5501304509877003
5	5	0.6938831806182861	0.5461508333695984	0.5441669772642564
6	6	0.6942597031593323	0.5461508333695984	0.5441669772642564
7	7	0.696772575378418	0.5515035467165673	0.5501304509877003
8	8	0.6956474781036377	0.5461508333695984	0.5441669772642564
9	9	0.7003608345985413	0.5515035467165673	0.5501304509877003
10	10	0.7023021578788757	0.5515035467165673	0.5501304509877003
11	11	0.6968831419944763	0.5461508333695984	0.5441669772642564
12	12	0.6960535049438477	0.5515035467165673	0.5501304509877003
13	13	0.6987209916114807	0.4721267244005396	0.4767051807677972
14	14	0.6968315839767456	0.5515035467165673	0.5501304509877003
15	15	0.6954220533370972	0.5515035467165673	0.5501304509877003
16	16	0.6927499771118164	0.5515035467165673	0.5501304509877003
17	17	0.6918821334838867	0.5461508333695984	0.5441669772642564
18	18	0.6920866966247559	0.5515035467165673	0.5501304509877003
19	19	0.6908444166183472	0.5461508333695984	0.5441669772642564
20	20	0.6932421922683716	0.4721702423952304	0.476332463660082
21	21	0.701454758644104	0.45384916663040165	0.45583302273574355
22	22	0.7002305388450623	0.5515035467165673	0.5501304509877003
23	23	0.698952853679657	0.5461508333695984	0.5441669772642564
24	24	0.6968458890914917	0.4721702423952304	0.476332463660082
