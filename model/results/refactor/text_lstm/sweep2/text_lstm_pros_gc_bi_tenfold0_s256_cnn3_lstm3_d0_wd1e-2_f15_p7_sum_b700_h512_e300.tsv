	epochs	train_losses	train_accs	dev_accs
0	0	0.6881763935089111	0.5461508333695984	0.5441669772642564
1	1	0.6885927319526672	0.5461508333695984	0.5441669772642564
2	2	0.6890621781349182	0.5461508333695984	0.5441669772642564
3	3	0.6891024708747864	0.5461508333695984	0.5441669772642564
4	4	0.6890926361083984	0.5461508333695984	0.5441669772642564
5	5	0.689420759677887	0.5461508333695984	0.5441669772642564
6	6	0.6893474459648132	0.5461508333695984	0.5441669772642564
7	7	0.689278781414032	0.5461508333695984	0.5441669772642564
8	8	0.6892621517181396	0.5461508333695984	0.5441669772642564
9	9	0.6893134713172913	0.5461508333695984	0.5441669772642564
10	10	0.6891722083091736	0.5461508333695984	0.5441669772642564
11	11	0.6893442273139954	0.5461508333695984	0.5441669772642564
12	12	0.6893815994262695	0.5461508333695984	0.5441669772642564
13	13	0.689483642578125	0.5461508333695984	0.5441669772642564
14	14	0.6892160177230835	0.5461508333695984	0.5441669772642564
15	15	0.6893294453620911	0.5461508333695984	0.5441669772642564
16	16	0.6893340945243835	0.5461508333695984	0.5441669772642564
17	17	0.6891807913780212	0.5461508333695984	0.5441669772642564
18	18	0.6892005205154419	0.5461508333695984	0.5441669772642564
19	19	0.6893283128738403	0.5461508333695984	0.5441669772642564
20	20	0.6892839670181274	0.5461508333695984	0.5441669772642564
21	21	0.689556360244751	0.5461508333695984	0.5441669772642564
22	22	0.6895864009857178	0.5461508333695984	0.5441669772642564
23	23	0.6894009113311768	0.5461508333695984	0.5441669772642564
24	24	0.6895149350166321	0.5461508333695984	0.5441669772642564
