	epochs	train_losses	train_accs	dev_accs
0	0	0.6661053895950317	0.5818340611353712	0.5855334538878842
1	1	0.6703000664710999	0.5841048034934497	0.5790235081374322
2	2	0.6798068284988403	0.5836681222707424	0.5779385171790236
3	3	0.6738230586051941	0.5852401746724891	0.5779385171790236
4	4	0.6709469556808472	0.5845851528384279	0.5772151898734177
5	5	0.6711591482162476	0.5819650655021834	0.58625678119349
6	6	0.6700282692909241	0.5796506550218341	0.5768535262206148
7	7	0.67264324426651	0.5836244541484716	0.5819168173598553
8	8	0.6656397581100464	0.5837554585152839	0.5801084990958408
9	9	0.6693133115768433	0.5713973799126637	0.5725135623869801
10	10	0.6665987372398376	0.5762008733624454	0.5735985533453888
11	11	0.6760934591293335	0.5844978165938864	0.5772151898734177
12	12	0.6653287410736084	0.5841048034934497	0.5790235081374322
13	13	0.6678949594497681	0.5836681222707424	0.5779385171790236
14	14	0.6718246340751648	0.5819650655021834	0.58625678119349
15	15	0.6659044027328491	0.5834497816593887	0.5783001808318264
16	16	0.6652415990829468	0.582882096069869	0.5851717902350814
17	17	0.6687730550765991	0.5841048034934497	0.5819168173598553
18	18	0.673980176448822	0.5852401746724891	0.5779385171790236
19	19	0.6710659861564636	0.582882096069869	0.5851717902350814
20	20	0.670538067817688	0.5818340611353712	0.5855334538878842
21	21	0.670049786567688	0.5819650655021834	0.58625678119349
22	22	0.66494220495224	0.582882096069869	0.5851717902350814
23	23	0.6656119227409363	0.584235807860262	0.5786618444846293
24	24	0.6667298674583435	0.5574235807860262	0.5396021699819168
