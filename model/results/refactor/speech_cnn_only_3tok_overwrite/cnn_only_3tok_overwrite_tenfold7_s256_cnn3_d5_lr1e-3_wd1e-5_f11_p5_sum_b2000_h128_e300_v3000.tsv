	epochs	train_losses	train_accs	dev_accs
0	0	0.6738674640655518	0.57651954491124	0.5821596244131455
1	1	0.6681883931159973	0.5719598034441542	0.5731052984574111
2	2	0.6767469644546509	0.5768736995882952	0.5831656606304494
3	3	0.6806914210319519	0.580061091681792	0.5942320590207915
4	4	0.677012026309967	0.5456195493381735	0.53420523138833
5	5	0.669577419757843	0.5710744167515163	0.5714285714285714
6	6	0.6720470786094666	0.5777590862809332	0.5881958417169685
7	7	0.6737388372421265	0.5807694010359025	0.5938967136150235
8	8	0.6706045269966125	0.5768736995882952	0.5855130784708249
9	9	0.6688137054443359	0.5803267076895834	0.5972501676727029
10	10	0.6905959248542786	0.519544911239984	0.5077129443326627
11	11	0.6716746091842651	0.5799282836778963	0.5888665325285044
12	12	0.6682134866714478	0.579175704989154	0.596579476861167
13	13	0.6713579297065735	0.5799282836778963	0.5892018779342723
14	14	0.7114441990852356	0.5710744167515163	0.5714285714285714
15	15	0.6722524166107178	0.5594758510779583	0.5586854460093896
16	16	0.676479697227478	0.5772278542653504	0.5858484238765929
17	17	0.6691551208496094	0.5803267076895834	0.5972501676727029
18	18	0.667680561542511	0.580061091681792	0.5959087860496312
19	19	0.671619176864624	0.5807694010359025	0.5949027498323273
20	20	0.671466588973999	0.5735977688255346	0.5761234071093226
21	21	0.675269603729248	0.5735977688255346	0.5761234071093226
22	22	0.6746101975440979	0.5716941874363628	0.5754527162977867
23	23	0.6725668907165527	0.5809022090397982	0.5952380952380952
24	24	0.6732286810874939	0.5719598034441542	0.5700871898054997
