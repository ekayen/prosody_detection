	epochs	train_losses	train_accs	dev_accs
0	0	0.6726922988891602	0.5853400836451684	0.579957356076759
1	1	0.6657262444496155	0.5847677745982831	0.57818052594172
2	2	0.6783978939056396	0.583579132731675	0.5810234541577826
3	3	0.6696137189865112	0.5839313229143738	0.5764036958066808
4	4	0.6745179891586304	0.5783843275368699	0.5764036958066808
5	5	0.6728549003601074	0.5689632401496808	0.5554371002132196
6	6	0.675025999546051	0.5802773497688752	0.587775408670931
7	7	0.6751800179481506	0.5837552278230245	0.5771144278606966
8	8	0.6618595123291016	0.5706361435174995	0.55863539445629
9	9	0.6635771989822388	0.5789566365837552	0.5675195451314854
10	10	0.7151293158531189	0.5450583314990095	0.5429992892679459
11	11	0.6712489128112793	0.5837112040501871	0.5749822316986496
12	12	0.6701033115386963	0.5809817301342725	0.587775408670931
13	13	0.6711761951446533	0.5855161787365177	0.579957356076759
14	14	0.6781966090202332	0.585824345146379	0.5767590618336887
15	15	0.6649513840675354	0.5825665859564164	0.5831556503198294
16	16	0.6656010150909424	0.5790446841294299	0.582089552238806
17	17	0.6698638200759888	0.5855161787365177	0.579957356076759
18	18	0.6834266781806946	0.5833149900946512	0.5835110163468372
19	19	0.6747600436210632	0.5837552278230245	0.5771144278606966
20	20	0.6667051315307617	0.5783843275368699	0.5764036958066808
21	21	0.6727039813995361	0.5838432753686991	0.5842217484008528
22	22	0.6627933979034424	0.5838432753686991	0.5842217484008528
23	23	0.6600559949874878	0.5839313229143738	0.5764036958066808
24	24	0.6674237847328186	0.5802773497688752	0.5881307746979388
