Unless otherwise indicated, the tokenization of the BURNC corpus is by breath marking alone.

<sent 1> . brth <sent2> . <sent3> brth <sent4>

would be segmented into

<sent 1>

<sent2> . <sent3>

<sent4>

Results summarized at https://docs.google.com/document/d/1S_gNifwGo7fwtLjZJCNfIBWDxkN6eqtHLRcPDALTUlc/edit
and at https://docs.google.com/spreadsheets/d/1NKo1wEPrLn2ikRgPZYhjdb5VcxKmjRhD9IQlF49nvRg/edit#gid=0 