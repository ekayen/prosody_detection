	epochs	train_losses	train_accs	dev_accs
0	0	0.5308481454849243	0.8267597492107253	0.8271059782608695
1	1	0.464886337518692	0.832184623593757	0.8359375
2	2	0.3925635814666748	0.840277468984837	0.8444293478260869
3	3	0.3594738245010376	0.8678020365512028	0.8678668478260869
4	4	0.3245311379432678	0.8417448530392636	0.8454483695652174
5	5	0.3057321310043335	0.880786162123705	0.8777173913043478
6	6	0.2963879108428955	0.8863889012406065	0.884171195652174
7	7	0.28756165504455566	0.8883898794966428	0.884171195652174
8	8	0.27840813994407654	0.8891458046155899	0.8868885869565217
9	9	0.27251383662223816	0.8937258215127396	0.8821331521739131
10	10	0.26656609773635864	0.8890124060651874	0.8834918478260869
11	11	0.26395201683044434	0.892925430210325	0.889266304347826
12	12	0.2622307240962982	0.889723865000667	0.8790760869565217
13	13	0.26326024532318115	0.8972831161901375	0.8879076086956522
14	14	0.2577211558818817	0.8999955533816533	0.8851902173913043
15	15	0.24689583480358124	0.8973275823736049	0.8862092391304348
16	16	0.24215807020664215	0.9054648939481524	0.8862092391304348
17	17	0.23578600585460663	0.9070656765529814	0.8855298913043478
18	18	0.23473072052001953	0.9083996620570056	0.8896059782608695
19	19	0.2309601902961731	0.9076437369380586	0.8862092391304348
20	20	0.2280627191066742	0.9154253190448663	0.8889266304347826
21	21	0.2168886363506317	0.9244074881052959	0.8950407608695652
22	22	0.20727287232875824	0.9262750678109298	0.8804347826086957
23	23	0.19989994168281555	0.9170705678331629	0.8654891304347826
24	24	0.19800281524658203	0.9233402997020765	0.881453804347826
