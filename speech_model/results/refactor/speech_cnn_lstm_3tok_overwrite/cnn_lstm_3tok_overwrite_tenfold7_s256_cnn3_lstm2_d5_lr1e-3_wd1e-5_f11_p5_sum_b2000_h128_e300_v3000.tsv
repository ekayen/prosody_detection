	epochs	train_losses	train_accs	dev_accs
0	0	0.6724107265472412	0.5803267076895834	0.5895372233400402
1	1	0.6693770289421082	0.5783788569657798	0.5898725687458082
2	2	0.6674650311470032	0.5803267076895834	0.5972501676727029
3	3	0.6695325374603271	0.5795741290008412	0.5895372233400402
4	4	0.6673955917358398	0.57651954491124	0.5821596244131455
5	5	0.672781765460968	0.5801496303510558	0.5881958417169685
6	6	0.6702910661697388	0.5786002036389393	0.5855130784708249
7	7	0.6683380007743835	0.5809022090397982	0.5952380952380952
8	8	0.673050582408905	0.5807694010359025	0.5938967136150235
9	9	0.6706938743591309	0.5802381690203197	0.5922199865861838
10	10	0.6669546365737915	0.5809022090397982	0.5952380952380952
11	11	0.6682848334312439	0.5803267076895834	0.5895372233400402
12	12	0.6711091995239258	0.5783788569657798	0.5898725687458082
13	13	0.6717772483825684	0.5795741290008412	0.5895372233400402
14	14	0.6673659086227417	0.5799282836778963	0.5915492957746479
15	15	0.6699145436286926	0.5809022090397982	0.5952380952380952
16	16	0.6745787858963013	0.5808136703705343	0.5949027498323273
17	17	0.6661127805709839	0.5807694010359025	0.5949027498323273
18	18	0.6751783490180969	0.5807694010359025	0.5938967136150235
19	19	0.6691285371780396	0.5807694010359025	0.5938967136150235
20	20	0.6741003394126892	0.5803267076895834	0.5895372233400402
21	21	0.6730986833572388	0.5799282836778963	0.5915492957746479
22	22	0.6754466891288757	0.5799282836778963	0.5915492957746479
23	23	0.6746174693107605	0.5799282836778963	0.5915492957746479
24	24	0.6684677600860596	0.5811678250475896	0.5952380952380952
