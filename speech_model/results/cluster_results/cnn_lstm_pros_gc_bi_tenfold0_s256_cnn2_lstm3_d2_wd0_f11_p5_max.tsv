	epochs	train_losses	train_accs	dev_accs
0	0	0.9712945222854614	0.4634231254623787	0.47111442415206856
1	1	0.8317978978157043	0.5447582575394926	0.5430488259411107
2	2	0.6941046714782715	0.5461943513642892	0.5441669772642564
3	3	0.6953371167182922	0.5599895556812742	0.5534849049571375
4	4	0.6959820985794067	0.5461508333695984	0.5441669772642564
5	5	0.693060040473938	0.5441054876191305	0.5415579575102497
6	6	0.6938816905021667	0.5461508333695984	0.5441669772642564
7	7	0.6953392028808594	0.5461508333695984	0.5441669772642564
8	8	0.6983997225761414	0.5461508333695984	0.5445396943719717
9	9	0.6962419152259827	0.45937595195613384	0.4576966082743198
10	10	0.6974067687988281	0.5461508333695984	0.5441669772642564
11	11	0.6993457674980164	0.5461508333695984	0.5441669772642564
12	12	0.6959407925605774	0.5461508333695984	0.5441669772642564
13	13	0.6928630471229553	0.5185604247356281	0.5244129705553485
14	14	0.7017520666122437	0.45384916663040165	0.45583302273574355
15	15	0.7029210329055786	0.5461508333695984	0.5441669772642564
16	16	0.7077075242996216	0.5461508333695984	0.5441669772642564
17	17	0.7305813431739807	0.5461508333695984	0.5441669772642564
18	18	0.7300801873207092	0.4570259802428304	0.4599329109206113
19	19	0.6925598978996277	0.5461508333695984	0.5441669772642564
20	20	0.6931042075157166	0.5461508333695984	0.5441669772642564
21	21	0.692572295665741	0.5453675094651639	0.5471487141259784
22	22	0.6936095356941223	0.5461508333695984	0.5441669772642564
23	23	0.6925520896911621	0.5461508333695984	0.5441669772642564
24	24	0.6906125545501709	0.5020235867531224	0.5072679836004472
