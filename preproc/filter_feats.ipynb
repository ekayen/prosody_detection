{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select only the necessary audio feats\n",
    "\n",
    "At this point, I have extracted all the audio features (MFCC+pitch). The file feats.scp serves as an index to these features, with the keys being utterance names, in SWBD-1 format.\n",
    "\n",
    "I also have a list of utterances in utterances.txt. The first element on each line is the utterance number in SWBD-NXT format; the second is the utterance number in SWBD-NXT format; the third is the list of tokens; the last is the list of labels.\n",
    "\n",
    "The goal here is to pull out all the keys from utterances.txt and use them to pull the actual features out, as indexed by feats.scp. Then make this into a python dictionary, where keys are utterance names (in SWBD-1 format) and values are numpy arrays that correspond to the MFCC+pitch feats for that utterance. Stores as a serialized file.\n",
    "\n",
    "This also generates a dictionary of labels, where the keys are utterance names, as above, and the values are the labels (in this case, as single binary value, where 1 indicates that the last token in the utterance is stressed and 0 indicates that it is not). Stores as a serialized file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import libraries and set filename variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaldi_io\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "feats_file = '/home/elizabeth/repos/kaldi/egs/swbd/s5c/data/train/feats_pitch.scp'\n",
    "#feats_file = '/afs/inf.ed.ac.uk/group/project/prosody/mfcc_pitch/feats.scp'\n",
    "data_file = 'data/utterances.txt'\n",
    "feat_dict_file = 'data/utterances_feats.pkl'\n",
    "label_dict_file = 'data/utterances_labels.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Load the utterances (tokens and labels in text format) and extract both labels and keys (the SWBD-1-formatted utterance names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sw2018A-ms98-a-0001</td>\n",
       "      <td>sw02018-A_000000-000376</td>\n",
       "      <td>hello this is lois</td>\n",
       "      <td>1 1 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sw2018A-ms98-a-0003</td>\n",
       "      <td>sw02018-A_000512-001158</td>\n",
       "      <td>and um i called you know from that the the ti ...</td>\n",
       "      <td>1 0 1 1 0 1 0 0 1 0 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sw2018A-ms98-a-0005</td>\n",
       "      <td>sw02018-A_001394-001810</td>\n",
       "      <td>yeah this is about changes in women in the</td>\n",
       "      <td>0 1 0 1 1 0 1 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sw2018A-ms98-a-0006</td>\n",
       "      <td>sw02018-A_001810-002363</td>\n",
       "      <td>uh there's really a lot isn't there i mean the...</td>\n",
       "      <td>0 0 1 0 1 1 1 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sw2018A-ms98-a-0008</td>\n",
       "      <td>sw02018-A_002467-003200</td>\n",
       "      <td>oh i guess the work force would be the main wo...</td>\n",
       "      <td>0 0 1 0 1 0 0 1 0 1 1 0 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7745</td>\n",
       "      <td>sw4890B-ms98-a-0055</td>\n",
       "      <td>sw04890-B_026274-026695</td>\n",
       "      <td>oh oh that's interesting</td>\n",
       "      <td>0 0 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7746</td>\n",
       "      <td>sw4890B-ms98-a-0057</td>\n",
       "      <td>sw04890-B_027482-027716</td>\n",
       "      <td>uh-huh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7747</td>\n",
       "      <td>sw4890B-ms98-a-0059</td>\n",
       "      <td>sw04890-B_028002-028154</td>\n",
       "      <td>oh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7748</td>\n",
       "      <td>sw4890B-ms98-a-0061</td>\n",
       "      <td>sw04890-B_028397-028688</td>\n",
       "      <td>oh i see</td>\n",
       "      <td>0 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7749</td>\n",
       "      <td>sw4890B-ms98-a-0063</td>\n",
       "      <td>sw04890-B_029591-029740</td>\n",
       "      <td>um-hum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7750 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0                        1  \\\n",
       "0     sw2018A-ms98-a-0001  sw02018-A_000000-000376   \n",
       "1     sw2018A-ms98-a-0003  sw02018-A_000512-001158   \n",
       "2     sw2018A-ms98-a-0005  sw02018-A_001394-001810   \n",
       "3     sw2018A-ms98-a-0006  sw02018-A_001810-002363   \n",
       "4     sw2018A-ms98-a-0008  sw02018-A_002467-003200   \n",
       "...                   ...                      ...   \n",
       "7745  sw4890B-ms98-a-0055  sw04890-B_026274-026695   \n",
       "7746  sw4890B-ms98-a-0057  sw04890-B_027482-027716   \n",
       "7747  sw4890B-ms98-a-0059  sw04890-B_028002-028154   \n",
       "7748  sw4890B-ms98-a-0061  sw04890-B_028397-028688   \n",
       "7749  sw4890B-ms98-a-0063  sw04890-B_029591-029740   \n",
       "\n",
       "                                                      2  \\\n",
       "0                                    hello this is lois   \n",
       "1     and um i called you know from that the the ti ...   \n",
       "2            yeah this is about changes in women in the   \n",
       "3     uh there's really a lot isn't there i mean the...   \n",
       "4     oh i guess the work force would be the main wo...   \n",
       "...                                                 ...   \n",
       "7745                           oh oh that's interesting   \n",
       "7746                                             uh-huh   \n",
       "7747                                                 oh   \n",
       "7748                                           oh i see   \n",
       "7749                                             um-hum   \n",
       "\n",
       "                                3  \n",
       "0                         1 1 0 1  \n",
       "1     1 0 1 1 0 1 0 0 1 0 1 1 1 1  \n",
       "2               0 1 0 1 1 0 1 0 0  \n",
       "3         0 0 1 0 1 1 1 1 0 0 1 1  \n",
       "4     0 0 1 0 1 0 0 1 0 1 1 0 1 0  \n",
       "...                           ...  \n",
       "7745                      0 0 0 1  \n",
       "7746                            0  \n",
       "7747                            0  \n",
       "7748                        0 0 1  \n",
       "7749                            0  \n",
       "\n",
       "[7750 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file,sep='\\t',header=None)\n",
    "labels = df.iloc[:,-1].tolist()\n",
    "keepkeys = df.iloc[:,1].tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.5:** Check to make sure these extracted lists make good sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW:\n",
      "0                                  sw2018B-ms98-a-0018\n",
      "1                              sw02018-B_004661-005898\n",
      "2    i know when my mother was a you know going int...\n",
      "3    0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 ...\n",
      "Name: 67, dtype: object\n",
      "LABEL:\n",
      "0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
      "KEY:\n",
      "sw02018-B_004661-005898\n"
     ]
    }
   ],
   "source": [
    "rownum = 67\n",
    "\n",
    "row = df.iloc[rownum]\n",
    "print('ROW:')\n",
    "print(row)\n",
    "print('LABEL:')\n",
    "print(labels[rownum])\n",
    "print('KEY:')\n",
    "print(keepkeys[rownum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Make labels into a dictionary where keys = utterance name, values = last token's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "zero_lens = []\n",
    "one_lens = []\n",
    "for i,key in enumerate(keepkeys):\n",
    "    label_dict[key] = torch.tensor(int(labels[i].split()[-1]))\n",
    "    if label_dict[key].item()==0:\n",
    "        zero_lens.append(len(labels[i]))\n",
    "    else:\n",
    "        one_lens.append(len(labels[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Quick, a data analysis aside: how often are unaccented final tokens just single tokens??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of 1 labels: 0.4984516129032258\n",
      "ModeResult(mode=array([1]), count=array([1302]))\n",
      "(3887,)\n",
      "ModeResult(mode=array([1]), count=array([745]))\n",
      "(3863,)\n"
     ]
    }
   ],
   "source": [
    "all_labels = [tens.tolist() for tens in list(label_dict.values())]\n",
    "print('Percent of 1 labels:',sum(all_labels)/len(all_labels))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "zero_lens = np.array(zero_lens)\n",
    "one_lens = np.array(one_lens)\n",
    "\n",
    "print(stats.mode(zero_lens))\n",
    "print(zero_lens.shape)\n",
    "\n",
    "print(stats.mode(one_lens))\n",
    "print(one_lens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm pretty often. Could be that these are backchannel-type tokens ('uh-huh', 'yeah', etc.) Check on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Go retrieve features and put into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering keys ...\n"
     ]
    }
   ],
   "source": [
    "feat_dict = {}\n",
    "print(\"filtering keys ...\")\n",
    "for key,mat in kaldi_io.read_mat_scp(feats_file):\n",
    "    if key in keepkeys:\n",
    "        feat_dict[key] = torch.tensor(mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** If you couldn't find a feature for an utterance, then drop the utterance from the label_dict as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feats = list(set(label_dict.keys())-set(feat_dict.keys()))\n",
    "\n",
    "for utt in missing_feats:\n",
    "    del label_dict[utt]\n",
    "    \n",
    "assert(len(label_dict)==len(feat_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Pickle the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(label_dict_file,'wb') as f:\n",
    "    pickle.dump(label_dict,f)\n",
    "\n",
    "with open(feat_dict_file,'wb') as f:\n",
    "    pickle.dump(feat_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
